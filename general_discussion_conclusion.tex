\section{General Discussion}

Decisions, even simple ones, may depend on context. Context effects occur when the relative choice for a given option varies with situational properties. In particular, the set of other available options affects choice. The attraction effect occurs when a decoy option boosts the choice share of a similar, superior target option. The repulsion effect, a reversal of the attraction effect, occurs when participants select the dissimilar competitor more than the target. 

This dissertation has explored context dependence in choice, largely by studying the attraction and repulsion effects (Chapters 2-4) but also through studying context dependence induced by the presentation format of options in perceptual choice (Chapter 5).

In Chapter 2, a Thurstonian choice model was developed to measure the correlations between valuations in the attraction and repulsion effects. Experiment 1 demonstrated systematic discriminability issues in a 2AFC task in accordance with the Thurstonian model. In Experiment 2, participants provided both valuations (area judgments for rectangles) and choices (participants selected the largest rectangle from each ternary choice set). The Thurstonian model, conditional on parameters estimated from the judgment data, was used to make predictions for the choice data. When the $\rho_{TD}$ parameter is greater than both the $\rho_{TC}$ and $\rho_{CD}$ parameters (as observed in the judgment data), the Thurstonian model can parsimoniously account for the repulsion effect without invoking higher-level decision processes (Experiment 2). Conditional on the observed parameters, the model cannot, however, account for the attraction effect, suggesting that higher-level decision processes may be required to explain this effect. 

In Chapter 3, the Thurstonian model was generalized to best-worst choice. In best-worst choice, participants select their most and least preferred options from a choice set. Given the stimuli from Experiment 2 (a set of target, competitor, and decoy rectangles in a perceptual choice experiment), the model predicts a non-monotonic relationship between best and worst choice probabilities. Specifically, the model predicts that the target is both less likely to be chosen as worst, compared to the competitor, and also less likely to be chosen as best. This effect is not predicted by the maxdiff model, a commonly used model for best-worst choice, when independently distributed utilities are assumed. These results were verified with empirical data in Experiment 3.

Chapter 4 generalized the paradigm and model from Chapter 2 to preferential choice. In Experiment 4, on each experimental trial, participants saw three consumer products (e.g., microwave ovens, laptops) and assigned each product a selling price. In later experimental trials, they saw the same three options and selected the option they preferred the most. The results of Experiment 4 found similar correlational patterns as found in Experiment 2. The choice results also replicated previous researchers' choice results \parencite{banerjeeFactorsThatPromote2024}, albeit with limitations described in the text.

The model from Experiment 4 is able to qualitatively account for the repulsion effect, with one crucial limitation; the model accounts for the repulsion effect through the correlation between target and decoy evaluations, which causes the decoy to take choice shares away from the target. In preferential choice, unlike in perceptual choice, participants seldom if ever select the decoy. In the absence of these correlations, or if all correlations are equal (i.e., $\rho_{TD}=\rho_{TC}=\rho_{CD}$), the model will be unable to predict the effect\footnote{See the diagonal line from Figure~\ref{fig:3d_model} for evidence of this theoretical result.}. Thus, the form of the repulsion effect in Experiment 4 may occur through higher-level decision processes, or a hitherto unidentified low-level process. Nonetheless, the demonstration of target-decoy correlations across choice environments is a novel result. Though other researchers have proposed correlations as a measure of the similarity between options in a choice set \parencite{kamakura1984predicting,natenzon2019random}, these studies were the first (to the author's knowledge) to systematically measure these correlations using valuations, incorporate them into a Thurstonian choice model, and connect this model to choices obtained from the same experimental participants.

Chapter 5 demonstrated a different form of context dependence, where choice systematically varied based on option comparability. In Chapter 5, Given a \textit{symmetrically dominated decoy} option, placing a focal target option in a nearby position, such that participants can more easily compare it to the decoy, caused a decrease in the target's choice share. 

The results of this dissertation have important methodological considerations. In particular researchers should carefully consider the assumptions made when designing and analyzing experiments. For example, the experiments of \textcite{spektorWhenGoodLooks2018b} contain a crucial assumption: that because participants chose the target more often the decoy, the repulsion effect cannot be explained by the decoy taking choice shares from the competitor. The results of Experiment 2 provide strong evidence that the repulsion effect can, on the contrary, be entirely explained by target-decoy correlations. Chapter 3 showed that the independence assumption of the maxdiff choice model is incorrect in certain cases and that a failure to consider whether the stimuli of a given experiment can cause these violations may lead to incorrect conclusions about participants' preferences. The results of Chapter 5 show that the comparability, and even order on screen, can systematically affect choice. Previous researchers have also argued in favor of this point \parencite{trueblood2022attentional,hasan2025registered,evansImpactPresentationOrder2021}. 

The approach outlined in Chapter 2 can be used for measurement purposes, specifically for measuring context effects in perceptual choice, after taking into account systematic covariance in perceptual noise. For example, the model showed that the repulsion effect, at least in the form demonstrated by \textcite{spektorWhenGoodLooks2018b}, can be generated entirely from a process by which the decoy takes choice shares away from the target, rather than one in which the competitor is systematically chosen over the target. \textcite{spektorRepulsionEffectPreferential2022} considered the possibility that the decoy was taking choice shares from the target, and they tested this hypothesis by estimating the parameters of a multinomial processing tree model. They considered the parameters implausible and dismissed the decoy similarity account on these grounds. The current approach minimizes these concerns because the parameters of the Thurstonian choice model were estimated independently of the choice data. 

Other researchers have introduced statistical measures of context effects. \textcite{berkowitschRigorouslyTestingMultialternative2014b} introduced the \textit{Relative Share of the Target} (RST), defined as the proportion of times the target is chosen over the competitor. \textcite{katsimpokisRobustBayesianTest2022} refined this measure by introducing \textit{Absolute Share of the Target} (AST), which corrects RST by equally weighting each choice set (e.g., $[A,B,D_{A}]$), reducing bias. These approaches, while valuable in statistically testing for context effects, do not test process accounts of context effects. RST and AST only test for whether the target is systematically chosen more or less often than the competitor. Neither RST nor AST can, for example, test the hypothesis that the decoy systematically takes away choice shares from the target. RST and AST are still quite useful; indeed, these measures were used to test for context effects in Experiments 2 and 5. Their utility stems from their ability to provide reliable statistical tests of context effects.

The current work identifies a crucial measurement factor - namely, correlations between valuations in perceptual choice - which has hitherto been ignored by decision researchers, with a few exceptions \parencite{kamakura1984predicting,natenzon2019random}. Future researchers should be able to use the current approach to identify data generating processes in various context effect data (e.g., compromise, similarity, phantom decoy effects). 

Other researchers have developed numerous cognitive process models to account for context effects \parencite{bergnerVAMPVotingAgent2019b,roeMultialternativeDecisionField2001a,trueblood2014multiattribute,wollschlager2NaryChoiceTree2012a,tversky1993context,tverskyEliminationAspectsTheory1972,bhatiaAssociationsAccumulationPreference2013b,spektor2019similarity,usherLossAversionInhibition2004a,noguchiMultialternativeDecisionSampling2018a}; these models are generally quite complex. Generally, researchers fit them to choice data by estimating free parameters from choice data. These parameters have strong psychological interpretations, such as loss aversion \parencite{usherLossAversionInhibition2004a}, extremeness aversion \parencite{trueblood2014multiattribute}, or lateral inhibition \parencite{roeMultialternativeDecisionField2001a}. However, success at identifying which model or mechanisms can best explain context effects has been mixed  \parencite{turnerCompetingTheoriesMultialternative2018a}. Furthermore, there have been limited attempts to test the psychological reality of these models' parameters or make a priori predictions from model mechanisms\footnote{See \textcite{cataldoFramingContextEffects2020}, \textcite{tsetsosPreferenceReversalMultiattribute2010a}, \textcite{hotalingTheoreticalDevelopmentsDecision2010}, and \textcite{trueblood2013not} for a few notable exceptions.}. The Thurstonian model is simpler and far more parsimonious than any of these cognitive process models. While it is almost certainly the case that additional mechanisms operate in the decision-maker's mind, we can also be fairly confident in the psychological reality of the mechanisms assumed by the Thurstonian model. For example, we have independent datasets across multiple paradigms supporting the case that $\rho_{TD}>\rho_{TC}$ and $\mu_{T}=\mu_{C}$. 

The correlations observed here could perhaps be incorporated into other models. For example, \textcite{roeMultialternativeDecisionField2001a}'s MDFT model includes within-trial correlations as a mechanism for accounting for the similarity effect; the current experimental results could provide a benchmark for across-trial correlations, which the MDFT and similar models need to satisfy.

Furthermore, though other researchers have hypothesized the aforementioned pattern of correlations \parencite{kamakura1984predicting,natenzon2019random}, the current work is the first (to the author's knowledge) to independently measure them using valuations and predict choice data, rather than simply estimating them freely from choice data.

This work also has implications for real-world decision-making. For example, the maxdiff model is frequently used in applied choice research \parencite{cheung2016using,beck2016best,flynn2014best,flynnBestWorstScaling2007,muhlbacher2016experimental}, as a method of identifying consumers' preferences. Though the model may work well when there are no systematic patterns of correlations, as observed in the current stimuli, when these patterns do exist, the researcher may be led astray by use of the maxdiff model with independent utilities. 

Applied researchers are also interested in using the multinomial probit (MNP) model to account for choice data \parencite{train2009discrete}. Identifying the model parameters can be complex, and to some extent, the model is a "black box". However, the current work provides a method for estimating the multinomial probit model parameters separately from choice data, such that the researcher can be more confident in the parameter estimates. Furthermore, to the extent that the model predictions agree with the choice data (as in Experiment 2, triangle condition), the researcher can be confident that no additional data generation processes are required to explain empirical results. Such a test can be more powerful than model-fitting or traditional cross-validation approaches.

There are numerous directions that this research could take, beyond this dissertation. Future work could generalize the experimental and modeling paradigm of Experiment 2 to other context effects (e.g., compromise, similarity, phantom decoy). Researchers should also measure correlations between option valuations at the individual participant level, which is currently limited by the quantity of data available. 

Regarding best-worst choice, future work should explore models of best-worst choice that can be used when the independence assumption is violated. Exploration or development of such models is necessary but is beyond the scope of this dissertation. However, given the numerous applied uses for best-worst choice, this avenue of research may improve researchers' ability to identify participants' preferences. 

Future work should also continue the line of research begun in Experiment 4. For example, research could collect both choice and pricing data from various binary and ternary sets. 

In addition to the experimental modifications discussed earlier, future work in comparability should generalize the paradigm to various choice types. Additionally, the effect observed in Experiment 5 was quite small; practically speaking, this may have limited impact on actual choices. Future work should address the limitations of comparability in affecting choice.

\section{Conclusions}
This dissertation has identified various forms of context dependence, in both perceptual and preferential choice. The research has provided theoretical explanations for these results in the form of a mathematical model of choice. To ensure falsifiability, The model's predictions were tested on out-of-sample data, to varying degrees of success. This work will further the study of context effects and decision-making in general. 